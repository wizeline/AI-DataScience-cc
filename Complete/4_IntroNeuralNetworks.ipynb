{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Overview\n",
    "\n",
    "During this session, you will participate in a supervised learning exercise about digit recognition. You will:\n",
    "- Build a neural network.\n",
    "- Train your neural network with a dataset that contains images that represent numbers. \n",
    "- Modify the architecture of the neural network to obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The MNIST data\n",
    "\n",
    "\n",
    "The MNIST data is comprised of pictures that represent a number and includes the number label associated to each picture. The data set is split into three data parts:\n",
    "- training (mnist.train)\n",
    "- testing (mnist.test)\n",
    "- validation (mnist.validation)\n",
    "\n",
    "The validation split is important because it's essential in machine learning that there is separate data which is not given to the machine during the learning phase. After the initial machine learning session, you present the separate data to the machine and assess the performance of it. The test and validation sets may serve different evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "mnist = input_data.read_data_sets(\"../Data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creating the model\n",
    "\n",
    "Common numerical computing libraries in Python use external code that is implemented in other languages to take advantage of their efficiency. However, switching back to Python for every operation causes overhead. This overhead is bad if you want to run computations on GPUs or in a distributed manner since there is a high cost to transfer data.\n",
    "\n",
    "TensorFlow does its heavy lifting outside of Python. Although it does not run expensive operations independently from Python, TensorFlow enables you to describe a graph of interacting operations that run entirely outside Python.\n",
    "\n",
    "#### TensorFlow Graph\n",
    "Create a TensorFlow graph that represents a neural network with no hidden layers and an output layer comprised of 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First Attempt - Slides\n",
    "image_size = 28*28\n",
    "number_digits = 10\n",
    "next_layer_neurons = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, image_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, number_digits])\n",
    "W = tf.Variable(tf.zeros([image_size, next_layer_neurons]))\n",
    "b = tf.Variable(tf.zeros([next_layer_neurons]))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second Attempt - Change Initialization\n",
    "image_size = 28*28\n",
    "number_digits = 10\n",
    "next_layer_neurons = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, image_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, number_digits])\n",
    "W = tf.Variable(tf.truncated_normal(shape=[image_size, next_layer_neurons],\n",
    "                                    mean=0.0,\n",
    "                                    stddev=1.0))\n",
    "b = tf.Variable(tf.truncated_normal(shape=[next_layer_neurons],\n",
    "                                    mean=0.0,\n",
    "                                    stddev=1.0))\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Third Attempt - Add a Hidden Layer\n",
    "image_size = 28*28\n",
    "number_digits = 10\n",
    "next_layer_neurons = 300\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, image_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, number_digits])\n",
    "\n",
    "# Hidden Layer\n",
    "shape1 = [image_size, next_layer_neurons]\n",
    "W1 = tf.Variable(tf.truncated_normal(shape=shape1,\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "b1 = tf.Variable(tf.truncated_normal(shape=[next_layer_neurons],\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "y1 = tf.matmul(x, W1) + b1\n",
    "\n",
    "# Output Layer\n",
    "shape2 = [next_layer_neurons, number_digits]\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=shape2,\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "b2 = tf.Variable(tf.truncated_normal(shape=[number_digits],\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "y = tf.matmul(y1, W2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fourth Attempt - Add Sigmoid\n",
    "image_size = 28*28\n",
    "number_digits = 10\n",
    "next_layer_neurons = 500\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, image_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, number_digits])\n",
    "\n",
    "# Hidden Layer\n",
    "shape1 = [image_size, next_layer_neurons]\n",
    "W1 = tf.Variable(tf.truncated_normal(shape=shape1,\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "b1 = tf.Variable(tf.truncated_normal(shape=[next_layer_neurons],\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "Y1 = tf.sigmoid(tf.matmul(x, W1) + b1)\n",
    "\n",
    "# Output Layer\n",
    "shape2 = [next_layer_neurons, number_digits]\n",
    "W2 = tf.Variable(tf.truncated_normal(shape=shape2,\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "b2 = tf.Variable(tf.truncated_normal(shape=[number_digits],\n",
    "                                     mean=0.0,\n",
    "                                     stddev=1.0))\n",
    "y = tf.matmul(Y1, W2) + b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Defining Cost Funtion and Optimizer\n",
    "\n",
    "In order to train the model, define what it means to improve the results after each iteration. Use a cost function and try to minimize with respect to it. The cost function represents how far you are from our desired outcome. Minimizing the error leads you towards improving the model.\n",
    "\n",
    "A common cost function is called *cross-entropy*. Cross-entropy takes advantage of large errors and reduces the learning slow down that is caused by using traditional cost functions (i.e. quadratic cost function). In summary, it will take less to train a good model.\n",
    "\n",
    "#### TensorFlow\n",
    "1. Create a tensor to represent the cross-entropy function. \n",
    "1. Create a tensor to represent a Gradient Descent Optimizer that minimizes the cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First Attempt - Slides\n",
    "cross_entropy = tf.reduce_mean(\n",
    "  tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "learn_rate = 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=learn_rate) \\\n",
    "             .minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Second Attempt - Change Optimizer\n",
    "cross_entropy = tf.reduce_mean(\n",
    "  tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n",
    "\n",
    "learn_rate = 0.01\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learn_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Creating a TensorFlow Session\n",
    "\n",
    "You have defined your model by creating a complete Tensorflow graph. Now, you need to launch it. Create an interactive session and initialize all the variables defined before.\n",
    "\n",
    "#### Interactive Session\n",
    "Create an Interactive Session and run the global variable initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Train\n",
    "\n",
    "MNIST is a large dataset. To train using a batch learning method is too time intensive in-between epochs. Therefore, use small batches of random data. This method is called stochastic training.\n",
    "\n",
    "#### Stochastic Training\n",
    "1. In a `for` loop, take 100 random samples from MNIST and run the train step using the resulting batches. \n",
    "1. Repeat the process as many times as necessary. \n",
    "1. Present all the training datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First Attempt - Slide\n",
    "# An epoch consists of running through all 55,000 observations once\n",
    "iterations = 55\n",
    "batch_size = 1000\n",
    "for _ in range(iterations):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second Attempt - Juggle Values\n",
    "# An epoch consists of running through all 55,000 observations once\n",
    "epochs = 10\n",
    "iterations = 1000\n",
    "batch_size = 55\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(iterations):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate your model\n",
    "\n",
    "To understand your model's precision, you need to compare your results with the expected output. To calculate the precision, you need to sum the correct classifications over the size of the testing dataset.\n",
    "#### Calculating Precision\n",
    "1. Create a Tensor that compares the model's output with the expected output. \n",
    "1. Determine the fraction that are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images,\n",
    "                                    y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Summary\n",
    "\n",
    "During the exercise you:\n",
    "- Learned how to create a neural network and train it. \n",
    "- Tested the performance of your model, and found that the network architecture definition is important to obtain better results.\n",
    "- Learned the importance of the initialization step (random numbers instead of zeroes), and how it impacts performance. \n",
    "- Reviewed the activation functionsâ€™ impact in performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
